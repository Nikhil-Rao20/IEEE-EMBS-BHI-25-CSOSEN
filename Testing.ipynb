{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc1b3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 All libraries imported successfully!\n",
      "📅 Analysis Date: 2025-10-03 17:29:17\n",
      "🔬 Disease-Specific Analysis with Advanced SHAP Integration - STATIC PLOTS ONLY\n"
     ]
    }
   ],
   "source": [
    "# 📚 Import Essential Libraries for Disease-Specific Analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning & Model Interpretation\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, LSTM, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Advanced SHAP Analysis\n",
    "import shap\n",
    "\n",
    "# Statistical Analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, kruskal, mannwhitneyu, chi2_contingency\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# File handling\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure plotting for beautiful static visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (14, 10)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"🚀 All libraries imported successfully!\")\n",
    "print(f\"📅 Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"🔬 Disease-Specific Analysis with Advanced SHAP Integration - STATIC PLOTS ONLY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c1479cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Base Path: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\n",
      "📁 Data Path: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Track1_Data\\processed\n",
      "📁 Results 12W Path: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\n",
      "📁 Models Path: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\All_Trained_Models\n",
      "📁 Disease Analysis Path: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\Disease_Specific_Analysis\n",
      "📁 Figures Path: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\Disease_Specific_Analysis\\figures\n",
      "📁 Tables Path: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\Disease_Specific_Analysis\\tables\n",
      "📁 Reports Path: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\Disease_Specific_Analysis\\reports\n",
      "✅ Feature metadata loaded: 8 features\n",
      "\n",
      "📊 Loading 12W dataset: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Track1_Data\\processed\\train_corrected_features.xlsx\n",
      "✅ Dataset loaded successfully!\n",
      "   Shape: (167, 26)\n",
      "   Columns: ['age', 'hospital_center_id', 'bdi_ii_baseline', 'mindfulness_therapies_started', 'mindfulness_therapies_completed', 'condition_cancer', 'condition_acute_coronary_syndrome', 'condition_renal_insufficiency', 'condition_lower_limb_amputation', 'condition_type_breast', 'condition_type_prostate', 'condition_type_revascularization', 'condition_type_no_prosthesis', 'condition_type_predialysis', 'condition_type_percutaneous_coronary_intervention', 'condition_type_dialysis', 'bdi_baseline_log', 'bdi_severity_category', 'bdi_baseline_squared', 'age_group', 'age_squared', 'therapy_completion_rate', 'therapy_engagement', 'sex_encoded', 'bdi_ii_after_intervention_12w', 'bdi_ii_follow_up_24w']\n",
      "\n",
      "📈 Dataset Overview:\n",
      "   Total samples: 167\n",
      "   Features: 26\n",
      "   Missing values: 0\n"
     ]
    }
   ],
   "source": [
    "# 📂 Load Results_12W Dataset and Setup Paths for Disease-Specific Analysis\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Setup paths for 12W results analysis\n",
    "current_dir = Path.cwd()\n",
    "src_track1_path = current_dir if current_dir.name == 'SRC_Track1' else current_dir / 'SRC_Track1'\n",
    "BASE_PATH = src_track1_path.parent\n",
    "DATA_PATH = BASE_PATH / \"Track1_Data\" / \"processed\"\n",
    "RESULTS_12W_PATH = BASE_PATH / \"Results_24W\"  # Focus on 12W results\n",
    "MODELS_PATH = BASE_PATH / \"All_Trained_Models\"\n",
    "\n",
    "# Create dedicated folder for disease-specific analysis within Results_12W\n",
    "DISEASE_ANALYSIS_PATH = RESULTS_12W_PATH / \"Disease_Specific_Analysis\"\n",
    "FIGURES_PATH = DISEASE_ANALYSIS_PATH / \"figures\"\n",
    "TABLES_PATH = DISEASE_ANALYSIS_PATH / \"tables\"\n",
    "REPORTS_PATH = DISEASE_ANALYSIS_PATH / \"reports\"\n",
    "\n",
    "# Add SRC_Track1 to path for model imports\n",
    "sys.path.append(str(BASE_PATH / \"SRC_Track1\"))\n",
    "\n",
    "# Create directories if they don't exist\n",
    "DISEASE_ANALYSIS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "TABLES_PATH.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"📁 Base Path: {BASE_PATH}\")\n",
    "print(f\"📁 Data Path: {DATA_PATH}\")\n",
    "print(f\"📁 Results 12W Path: {RESULTS_12W_PATH}\")\n",
    "print(f\"📁 Models Path: {MODELS_PATH}\")\n",
    "print(f\"📁 Disease Analysis Path: {DISEASE_ANALYSIS_PATH}\")\n",
    "print(f\"📁 Figures Path: {FIGURES_PATH}\")\n",
    "print(f\"📁 Tables Path: {TABLES_PATH}\")\n",
    "print(f\"📁 Reports Path: {REPORTS_PATH}\")\n",
    "\n",
    "# Load feature metadata if available\n",
    "try:\n",
    "    feature_metadata_file = DATA_PATH / \"corrected_feature_documentation.json\"\n",
    "    if feature_metadata_file.exists():\n",
    "        with open(feature_metadata_file, 'r') as f:\n",
    "            feature_metadata = json.load(f)\n",
    "        print(f\"✅ Feature metadata loaded: {len(feature_metadata)} features\")\n",
    "    else:\n",
    "        feature_metadata = None\n",
    "        print(\"⚠️ Feature metadata not found - will use indices\")\n",
    "except Exception as e:\n",
    "    feature_metadata = None\n",
    "    print(f\"⚠️ Could not load feature metadata: {e}\")\n",
    "\n",
    "# Load the main 12W training dataset\n",
    "results_file = DATA_PATH / \"train_corrected_features.xlsx\"\n",
    "\n",
    "if results_file.exists():\n",
    "    print(f\"\\n📊 Loading 12W dataset: {results_file}\")\n",
    "    train_data = pd.read_excel(results_file)\n",
    "    print(f\"✅ Dataset loaded successfully!\")\n",
    "    print(f\"   Shape: {train_data.shape}\")\n",
    "    print(f\"   Columns: {list(train_data.columns)}\")\n",
    "    \n",
    "    # Display basic info\n",
    "    print(f\"\\n📈 Dataset Overview:\")\n",
    "    print(f\"   Total samples: {len(train_data)}\")\n",
    "    print(f\"   Features: {train_data.shape[1]}\")\n",
    "    print(f\"   Missing values: {train_data.isnull().sum().sum()}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"❌ Dataset file not found: {results_file}\")\n",
    "    print(\"Available files in Results_12W:\")\n",
    "    if RESULTS_12W_PATH.exists():\n",
    "        for file in RESULTS_12W_PATH.glob(\"*.csv\"):\n",
    "            print(f\"   {file.name}\")\n",
    "    else:\n",
    "        print(\"   Results_12W directory not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "970769a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Experiment Framework Initialized\n",
      "📁 Results will be saved to: ..\\Results\\Model_Experiments\n",
      "🆔 Experiment ID: 20251003_174029\n",
      "🎲 Random Seed: 42\n",
      "🤖 Found 43 pre-trained model configurations\n",
      "\n",
      "🏆 Top 5 Models by R² Score for 12W:\n",
      "   Rank  1: phase3_catboost           R²:  0.200 MAE:  4.365\n",
      "   Rank  2: phase4_mlp_large          R²:  0.168 MAE:  4.638\n",
      "   Rank  3: phase5_rf_trajectory      R²:  0.155 MAE:  4.799\n",
      "   Rank  4: phase4_mlp_medium         R²:  0.145 MAE:  4.734\n",
      "   Rank  5: phase2_random_forest      R²:  0.139 MAE:  4.519\n",
      "\n",
      "🤖 Transformer Models Available:\n",
      "   Rank 20: phase5_transformer        R²:  0.088 MAE:  4.973\n",
      "\n",
      "✅ Selected Transformer: phase5_transformer\n",
      "\n",
      "🎯 Ready for Disease-Specific Analysis with Efficient Model Loading!\n"
     ]
    }
   ],
   "source": [
    "# 🤖 Efficient Model Loader System for Disease-Specific Analysis\n",
    "# Import the experiment framework and phase modules to recreate models\n",
    "from experiment_framework import ExperimentFramework\n",
    "from phase1_baseline_models import Phase1BaselineModels\n",
    "from phase2_classical_ml import Phase2ClassicalML\n",
    "from phase3_advanced_ensembles import Phase3AdvancedEnsembles\n",
    "from phase5_timeseries import Phase5TimeSeriesModels\n",
    "\n",
    "class ResultsBasedModelLoader:\n",
    "    \"\"\"Load and recreate models from phase results JSON files\"\"\"\n",
    "    \n",
    "    def __init__(self, results_dir):\n",
    "        self.results_dir = Path(results_dir)\n",
    "        self.available_models = []\n",
    "        self.framework = ExperimentFramework(random_seed=42)\n",
    "        self._discover_models()\n",
    "    \n",
    "    def _discover_models(self):\n",
    "        \"\"\"Discover available models from phase results\"\"\"\n",
    "        phase_files = list(self.results_dir.glob(\"phase*_results_*.json\"))\n",
    "        \n",
    "        for phase_file in sorted(phase_files):\n",
    "            try:\n",
    "                with open(phase_file, 'r') as f:\n",
    "                    results = json.load(f)\n",
    "                \n",
    "                phase_name = phase_file.stem.split('_results_')[0]\n",
    "                \n",
    "                for model_name, model_data in results.items():\n",
    "                    if isinstance(model_data, dict) and 'mean_scores' in model_data:\n",
    "                        mae = model_data['mean_scores'].get('test_mae', float('inf'))\n",
    "                        r2 = model_data['mean_scores'].get('test_r2', -float('inf'))\n",
    "                        \n",
    "                        self.available_models.append({\n",
    "                            'model_id': f\"{phase_name}_{model_name}\",\n",
    "                            'phase': phase_name,\n",
    "                            'model_name': model_name,\n",
    "                            'mae': mae,\n",
    "                            'r2': r2,\n",
    "                            'results_file': phase_file,\n",
    "                            'model_data': model_data\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not load {phase_file}: {e}\")\n",
    "        \n",
    "        # Sort by R² (best first)\n",
    "        self.available_models.sort(key=lambda x: x['r2'], reverse=True)\n",
    "        \n",
    "        # Add ranks\n",
    "        for i, model in enumerate(self.available_models):\n",
    "            model['rank'] = i + 1\n",
    "    \n",
    "    def get_best_models(self, top_n=5):\n",
    "        \"\"\"Get top N models by R² score\"\"\"\n",
    "        return self.available_models[:top_n]\n",
    "    \n",
    "    def get_transformer_models(self):\n",
    "        \"\"\"Get all transformer models\"\"\"\n",
    "        return [model for model in self.available_models if 'transformer' in model['model_name'].lower()]\n",
    "    \n",
    "    def recreate_model(self, model_info, X, y):\n",
    "        \"\"\"Recreate and train a model based on the stored results\"\"\"\n",
    "        phase = model_info['phase']\n",
    "        model_name = model_info['model_name']\n",
    "        model_data = model_info['model_data']\n",
    "        \n",
    "        print(f\"🔧 Recreating {phase}_{model_name}...\")\n",
    "        \n",
    "        if phase == 'phase1':\n",
    "            phase_module = Phase1BaselineModels(self.framework)\n",
    "            models = phase_module.create_models()\n",
    "        elif phase == 'phase2':\n",
    "            phase_module = Phase2ClassicalML(random_seed=42)\n",
    "            models = phase_module.create_models()\n",
    "        elif phase == 'phase3':\n",
    "            phase_module = Phase3AdvancedEnsembles(random_seed=42)\n",
    "            models = phase_module.create_models()\n",
    "        elif phase == 'phase5':\n",
    "            phase_module = Phase5TimeSeriesModels(random_seed=42)\n",
    "            models = phase_module.create_models(X, y)\n",
    "        else:\n",
    "            raise ValueError(f\"Phase {phase} not supported yet\")\n",
    "        \n",
    "        # Get the model\n",
    "        if model_name not in models:\n",
    "            print(f\"   Available models in {phase}: {list(models.keys())}\")\n",
    "            raise ValueError(f\"Model {model_name} not found in {phase}\")\n",
    "        \n",
    "        model = models[model_name]\n",
    "        \n",
    "        # Apply best hyperparameters if available\n",
    "        if 'best_params' in model_data:\n",
    "            best_params = model_data['best_params']\n",
    "            print(f\"   Applying best params: {list(best_params.keys())}\")\n",
    "            \n",
    "            try:\n",
    "                model.set_params(**best_params)\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️ Could not set all params: {e}\")\n",
    "                # Try to set individual parameters that exist\n",
    "                for param, value in best_params.items():\n",
    "                    try:\n",
    "                        model.set_params(**{param: value})\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # Train the model\n",
    "        print(f\"   Training {model_name}...\")\n",
    "        if phase == 'phase5':\n",
    "            # Phase5 models need sequence data for fitting\n",
    "            X_seq, y_seq = phase_module.create_sequence_features(X, y, sequence_length=5)\n",
    "            print(f\"   Using sequence data shape: X_seq={X_seq.shape}, y_seq={y_seq.shape}\")\n",
    "            model.fit(X_seq, y_seq)\n",
    "        else:\n",
    "            # Phase1, Phase2, and Phase3 use regular fitting\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        print(f\"   ✅ Model trained successfully\")\n",
    "        \n",
    "        return model, phase_module if phase == 'phase5' else None\n",
    "\n",
    "# Initialize the model loader for 12W results\n",
    "results_dir = RESULTS_12W_PATH / \"Model_Experiments\"\n",
    "if results_dir.exists():\n",
    "    model_loader = ResultsBasedModelLoader(results_dir)\n",
    "    \n",
    "    print(f\"🤖 Found {len(model_loader.available_models)} pre-trained model configurations\")\n",
    "    \n",
    "    # Show top 5 models by R² score\n",
    "    best_models = model_loader.get_best_models(5)\n",
    "    print(f\"\\n🏆 Top 5 Models by R² Score for 12W:\")\n",
    "    for model in best_models:\n",
    "        print(f\"   Rank {model['rank']:2d}: {model['model_id']:25s} R²: {model['r2']:6.3f} MAE: {model['mae']:6.3f}\")\n",
    "    \n",
    "    # Get transformer models specifically\n",
    "    transformer_models = model_loader.get_transformer_models()\n",
    "    if transformer_models:\n",
    "        print(f\"\\n🤖 Transformer Models Available:\")\n",
    "        for model in transformer_models:\n",
    "            print(f\"   Rank {model['rank']:2d}: {model['model_id']:25s} R²: {model['r2']:6.3f} MAE: {model['mae']:6.3f}\")\n",
    "        \n",
    "        # Select the best transformer for disease-specific analysis\n",
    "        best_transformer = transformer_models[0]\n",
    "        selected_model_info = best_transformer\n",
    "        print(f\"\\n✅ Selected Transformer: {best_transformer['model_id']}\")\n",
    "    else:\n",
    "        # If no transformer, use the best overall model\n",
    "        selected_model_info = best_models[0]\n",
    "        print(f\"\\n✅ Selected Best Model: {selected_model_info['model_id']}\")\n",
    "        \n",
    "else:\n",
    "    print(f\"❌ Results directory not found: {results_dir}\")\n",
    "    print(\"   Will use a simple Random Forest for disease-specific analysis\")\n",
    "    model_loader = None\n",
    "    selected_model_info = None\n",
    "\n",
    "print(f\"\\n🎯 Ready for Disease-Specific Analysis with Efficient Model Loading!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a3cebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏥 Setting up Disease-Specific Analysis...\n",
      "📊 Available columns in dataset: ['age', 'hospital_center_id', 'bdi_ii_baseline', 'mindfulness_therapies_started', 'mindfulness_therapies_completed', 'condition_cancer', 'condition_acute_coronary_syndrome', 'condition_renal_insufficiency', 'condition_lower_limb_amputation', 'condition_type_breast', 'condition_type_prostate', 'condition_type_revascularization', 'condition_type_no_prosthesis', 'condition_type_predialysis', 'condition_type_percutaneous_coronary_intervention', 'condition_type_dialysis', 'bdi_baseline_log', 'bdi_severity_category', 'bdi_baseline_squared', 'age_group', 'age_squared', 'therapy_completion_rate', 'therapy_engagement', 'sex_encoded', 'bdi_ii_after_intervention_12w', 'bdi_ii_follow_up_24w']\n",
      "🎯 Target variable: bdi_ii_after_intervention_12w\n",
      "📊 Feature columns: 24 features\n",
      "🚫 Excluded columns: ['Unnamed: 0', 'bdi_ii_after_intervention_12w', 'bdi_ii_after_intervention_24w', 'hospital_center_id', 'patient_id']\n",
      "🏥 Identified condition features: ['condition_cancer', 'condition_acute_coronary_syndrome', 'condition_renal_insufficiency', 'condition_lower_limb_amputation', 'condition_type_breast', 'condition_type_prostate', 'condition_type_revascularization', 'condition_type_no_prosthesis', 'condition_type_predialysis', 'condition_type_percutaneous_coronary_intervention', 'condition_type_dialysis']\n",
      "📊 Data prepared for analysis:\n",
      "   Features shape: (167, 24)\n",
      "   Target shape: (167,)\n",
      "   Target variable: bdi_ii_after_intervention_12w\n",
      "✅ Features standardized\n",
      "\n",
      "🏥 Disease Group Distribution:\n",
      "   Cancer: 108 patients (64.7%) - Mean BDI: 8.51\n",
      "   Cardiovascular: 39 patients (23.4%) - Mean BDI: 5.38\n",
      "   Renal: 10 patients (6.0%) - Mean BDI: 3.50\n",
      "   Musculoskeletal: 10 patients (6.0%) - Mean BDI: 8.50\n",
      "\n",
      "📊 Condition Complexity Distribution:\n",
      "   2 conditions: 167 patients (100.0%) - Mean BDI: 7.48\n",
      "\n",
      "📈 Statistical Analysis by Disease Group:\n",
      "   ANOVA F-statistic: 2.967, p-value: 0.0337\n",
      "   Kruskal-Wallis H-statistic: 10.474, p-value: 0.0149\n",
      "   ✅ Significant differences between disease groups (p < 0.05)\n",
      "\n",
      "✅ Disease-specific data preparation complete!\n",
      "   Disease groups identified: 4\n",
      "   Largest group: Cancer (108 patients)\n",
      "   Most complex case: 2 conditions\n",
      "\n",
      "🔬 Preparing for disease-specific feature importance analysis...\n",
      "   Cancer: 108 samples, mean BDI: 8.51 ± 7.65\n",
      "   Cardiovascular: 39 samples, mean BDI: 5.38 ± 5.05\n",
      "   Renal: 10 samples, mean BDI: 3.50 ± 5.82\n",
      "   Musculoskeletal: 10 samples, mean BDI: 8.50 ± 8.22\n",
      "\n",
      "🎯 Ready for model training and disease-specific analysis!\n"
     ]
    }
   ],
   "source": [
    "# 🏥 Disease-Specific Analysis Setup and Data Preparation\n",
    "print(\"🏥 Setting up Disease-Specific Analysis...\")\n",
    "\n",
    "# Check available columns in the dataset\n",
    "print(f\"📊 Available columns in dataset: {list(train_data.columns)}\")\n",
    "\n",
    "# Define target column and feature columns\n",
    "target_col = 'bdi_ii_after_intervention_12w'  # The BDI score after 12-week intervention\n",
    "\n",
    "# Exclude columns that shouldn't be features\n",
    "exclude_cols = {\n",
    "    'bdi_ii_after_intervention_12w',  # Target variable\n",
    "    'bdi_ii_after_intervention_24w',  # Future target (24w)\n",
    "    'patient_id',  # ID column\n",
    "    'Unnamed: 0'   # Index column if present\n",
    "}\n",
    "\n",
    "# Add any additional exclusions based on what we find in the data\n",
    "additional_excludes = [col for col in train_data.columns if \n",
    "                      'id' in col.lower() or \n",
    "                      'unnamed' in col.lower() or\n",
    "                      col.startswith('_')]\n",
    "\n",
    "exclude_cols.update(additional_excludes)\n",
    "\n",
    "# Define feature columns (all columns except excluded ones)\n",
    "feature_cols = [col for col in train_data.columns if col not in exclude_cols]\n",
    "\n",
    "print(f\"🎯 Target variable: {target_col}\")\n",
    "print(f\"📊 Feature columns: {len(feature_cols)} features\")\n",
    "print(f\"🚫 Excluded columns: {sorted(exclude_cols)}\")\n",
    "\n",
    "# Verify target column exists\n",
    "if target_col not in train_data.columns:\n",
    "    # Try alternative target names\n",
    "    possible_targets = [col for col in train_data.columns if 'bdi' in col.lower() and ('12w' in col.lower() or 'after' in col.lower())]\n",
    "    if possible_targets:\n",
    "        target_col = possible_targets[0]\n",
    "        print(f\"⚠️ Using alternative target: {target_col}\")\n",
    "    else:\n",
    "        # Use any BDI column as fallback\n",
    "        bdi_cols = [col for col in train_data.columns if 'bdi' in col.lower()]\n",
    "        if bdi_cols:\n",
    "            target_col = bdi_cols[0]\n",
    "            print(f\"⚠️ Using fallback target: {target_col}\")\n",
    "        else:\n",
    "            print(\"❌ No suitable target column found!\")\n",
    "            target_col = train_data.columns[-1]  # Last column as fallback\n",
    "            print(f\"⚠️ Using last column as target: {target_col}\")\n",
    "\n",
    "# Identify condition/medical features from the dataset\n",
    "condition_features = [col for col in train_data.columns if any(keyword in col.lower() for keyword in \n",
    "                     ['condition', 'cancer', 'cardiovascular', 'coronary', 'renal', 'dialysis', \n",
    "                      'amputation', 'breast', 'prostate', 'revascularization', 'predialysis'])]\n",
    "\n",
    "print(f\"🏥 Identified condition features: {condition_features}\")\n",
    "\n",
    "# If no specific condition features found, use binary features that might represent conditions\n",
    "if not condition_features:\n",
    "    # Look for binary features (0/1) that might represent medical conditions\n",
    "    binary_features = []\n",
    "    for col in train_data.columns:\n",
    "        if train_data[col].dtype in ['int64', 'float64'] and set(train_data[col].dropna().unique()).issubset({0, 1, 0.0, 1.0}):\n",
    "            binary_features.append(col)\n",
    "    \n",
    "    # Filter out obvious non-condition features\n",
    "    exclude_keywords = ['target', 'bdi', 'after', 'before', 'age', 'gender', 'sex', 'id', 'time']\n",
    "    condition_features = [col for col in binary_features if not any(keyword in col.lower() for keyword in exclude_keywords)]\n",
    "    \n",
    "    print(f\"🔍 Using binary features as potential conditions: {len(condition_features)} features\")\n",
    "    if len(condition_features) > 20:\n",
    "        condition_features = condition_features[:20]  # Limit to first 20 to avoid too many\n",
    "        print(f\"📝 Limited to first 20 condition features\")\n",
    "\n",
    "# Prepare data for analysis\n",
    "X = train_data[feature_cols].values\n",
    "y = train_data[target_col].values\n",
    "\n",
    "print(f\"📊 Data prepared for analysis:\")\n",
    "print(f\"   Features shape: {X.shape}\")\n",
    "print(f\"   Target shape: {y.shape}\")\n",
    "print(f\"   Target variable: {target_col}\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(f\"✅ Features standardized\")\n",
    "\n",
    "# Create disease type mapping based on condition features\n",
    "def create_disease_groups(data, condition_features):\n",
    "    \"\"\"Create disease groups based on condition features\"\"\"\n",
    "    disease_groups = {}\n",
    "    \n",
    "    for idx, row in data.iterrows():\n",
    "        patient_conditions = []\n",
    "        \n",
    "        # Check each condition feature\n",
    "        for condition in condition_features:\n",
    "            if condition in data.columns and row[condition] == 1:\n",
    "                patient_conditions.append(condition)\n",
    "        \n",
    "        # Classify into disease groups based on condition names\n",
    "        if len(patient_conditions) == 0:\n",
    "            group = 'No_Specific_Condition'\n",
    "        elif any('cancer' in cond.lower() or 'breast' in cond.lower() or 'prostate' in cond.lower() for cond in patient_conditions):\n",
    "            group = 'Cancer'\n",
    "        elif any('cardiovascular' in cond.lower() or 'coronary' in cond.lower() or 'revascularization' in cond.lower() for cond in patient_conditions):\n",
    "            group = 'Cardiovascular'\n",
    "        elif any('renal' in cond.lower() or 'dialysis' in cond.lower() or 'predialysis' in cond.lower() for cond in patient_conditions):\n",
    "            group = 'Renal'\n",
    "        elif any('amputation' in cond.lower() for cond in patient_conditions):\n",
    "            group = 'Musculoskeletal'\n",
    "        else:\n",
    "            # For generic binary features, create groups based on number of conditions\n",
    "            if len(patient_conditions) >= 3:\n",
    "                group = 'Multiple_Conditions'\n",
    "            elif len(patient_conditions) == 2:\n",
    "                group = 'Dual_Conditions'\n",
    "            elif len(patient_conditions) == 1:\n",
    "                group = 'Single_Condition'\n",
    "            else:\n",
    "                group = 'No_Conditions'\n",
    "        \n",
    "        disease_groups[idx] = {\n",
    "            'group': group,\n",
    "            'conditions': patient_conditions,\n",
    "            'condition_count': len(patient_conditions)\n",
    "        }\n",
    "    \n",
    "    return disease_groups\n",
    "\n",
    "# Create disease groups\n",
    "disease_mapping = create_disease_groups(train_data, condition_features)\n",
    "\n",
    "# Convert to arrays for analysis\n",
    "disease_groups = [disease_mapping[i]['group'] for i in range(len(train_data))]\n",
    "condition_counts = [disease_mapping[i]['condition_count'] for i in range(len(train_data))]\n",
    "\n",
    "# Add disease groups to dataframe for analysis\n",
    "train_data_analysis = train_data.copy()\n",
    "train_data_analysis['disease_group'] = disease_groups\n",
    "train_data_analysis['condition_count'] = condition_counts\n",
    "\n",
    "print(f\"\\n🏥 Disease Group Distribution:\")\n",
    "group_counts = pd.Series(disease_groups).value_counts()\n",
    "for group, count in group_counts.items():\n",
    "    percentage = (count / len(disease_groups)) * 100\n",
    "    mean_bdi = train_data_analysis[train_data_analysis['disease_group'] == group][target_col].mean()\n",
    "    print(f\"   {group}: {count} patients ({percentage:.1f}%) - Mean BDI: {mean_bdi:.2f}\")\n",
    "\n",
    "print(f\"\\n📊 Condition Complexity Distribution:\")\n",
    "complexity_dist = pd.Series(condition_counts).value_counts().sort_index()\n",
    "for count, freq in complexity_dist.items():\n",
    "    percentage = (freq / len(condition_counts)) * 100\n",
    "    mean_bdi = train_data_analysis[train_data_analysis['condition_count'] == count][target_col].mean()\n",
    "    print(f\"   {count} conditions: {freq} patients ({percentage:.1f}%) - Mean BDI: {mean_bdi:.2f}\")\n",
    "\n",
    "# Statistical analysis of disease groups\n",
    "print(f\"\\n📈 Statistical Analysis by Disease Group:\")\n",
    "from scipy.stats import f_oneway, kruskal\n",
    "\n",
    "# Perform ANOVA to test for differences between groups\n",
    "groups_for_anova = []\n",
    "group_names = group_counts.index.tolist()\n",
    "\n",
    "for group in group_names:\n",
    "    group_data = train_data_analysis[train_data_analysis['disease_group'] == group][target_col].values\n",
    "    groups_for_anova.append(group_data)\n",
    "\n",
    "# ANOVA test\n",
    "if len(group_names) > 1:\n",
    "    f_stat, p_value_anova = f_oneway(*groups_for_anova)\n",
    "    print(f\"   ANOVA F-statistic: {f_stat:.3f}, p-value: {p_value_anova:.4f}\")\n",
    "    \n",
    "    # Kruskal-Wallis test (non-parametric alternative)\n",
    "    h_stat, p_value_kruskal = kruskal(*groups_for_anova)\n",
    "    print(f\"   Kruskal-Wallis H-statistic: {h_stat:.3f}, p-value: {p_value_kruskal:.4f}\")\n",
    "    \n",
    "    if p_value_anova < 0.05:\n",
    "        print(f\"   ✅ Significant differences between disease groups (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"   ⚠️ No significant differences between disease groups (p ≥ 0.05)\")\n",
    "\n",
    "# Prepare visualization data\n",
    "visualization_data = {\n",
    "    'disease_groups': disease_groups,\n",
    "    'condition_counts': condition_counts,\n",
    "    'group_counts': group_counts,\n",
    "    'complexity_dist': complexity_dist,\n",
    "    'train_data_analysis': train_data_analysis\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ Disease-specific data preparation complete!\")\n",
    "print(f\"   Disease groups identified: {len(group_counts)}\")\n",
    "print(f\"   Largest group: {group_counts.index[0]} ({group_counts.iloc[0]} patients)\")\n",
    "print(f\"   Most complex case: {max(condition_counts)} conditions\")\n",
    "\n",
    "# Create disease-specific feature importance analysis preparation\n",
    "print(f\"\\n🔬 Preparing for disease-specific feature importance analysis...\")\n",
    "disease_feature_data = {}\n",
    "\n",
    "for group in group_names:\n",
    "    group_mask = train_data_analysis['disease_group'] == group\n",
    "    group_X = X_scaled[group_mask]\n",
    "    group_y = y[group_mask]\n",
    "    \n",
    "    disease_feature_data[group] = {\n",
    "        'X': group_X,\n",
    "        'y': group_y,\n",
    "        'n_samples': len(group_y),\n",
    "        'mean_target': np.mean(group_y),\n",
    "        'std_target': np.std(group_y)\n",
    "    }\n",
    "    \n",
    "    print(f\"   {group}: {len(group_y)} samples, mean BDI: {np.mean(group_y):.2f} ± {np.std(group_y):.2f}\")\n",
    "\n",
    "print(f\"\\n🎯 Ready for model training and disease-specific analysis!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f8bd479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔬 Experiment Framework Initialized\n",
      "📁 Results will be saved to: ..\\Results\\Model_Experiments\n",
      "🆔 Experiment ID: 20251003_174030\n",
      "🎲 Random Seed: 42\n",
      "🤖 Found 43 pre-trained model configurations\n",
      "\n",
      "🏆 Top 5 Models by R² Score:\n",
      "   Rank  1: phase3_catboost           R²:  0.200 MAE:  4.365\n",
      "   Rank  2: phase4_mlp_large          R²:  0.168 MAE:  4.638\n",
      "   Rank  3: phase5_rf_trajectory      R²:  0.155 MAE:  4.799\n",
      "   Rank  4: phase4_mlp_medium         R²:  0.145 MAE:  4.734\n",
      "   Rank  5: phase2_random_forest      R²:  0.139 MAE:  4.519\n"
     ]
    }
   ],
   "source": [
    "# 🤖 Pre-trained Model Loader System with Phase3, Phase5 Transformer Support\n",
    "# Import the experiment framework and phase modules to recreate models\n",
    "from experiment_framework import ExperimentFramework\n",
    "from phase1_baseline_models import Phase1BaselineModels\n",
    "from phase2_classical_ml import Phase2ClassicalML\n",
    "from phase3_advanced_ensembles import Phase3AdvancedEnsembles\n",
    "from phase5_timeseries import Phase5TimeSeriesModels\n",
    "\n",
    "class ResultsBasedModelLoader:\n",
    "    \"\"\"Load and recreate models from phase results JSON files\"\"\"\n",
    "    \n",
    "    def __init__(self, results_dir):\n",
    "        self.results_dir = Path(results_dir)\n",
    "        self.available_models = []\n",
    "        self.framework = ExperimentFramework(random_seed=42)\n",
    "        self._discover_models()\n",
    "    \n",
    "    def _discover_models(self):\n",
    "        \"\"\"Discover available models from phase results\"\"\"\n",
    "        phase_files = list(self.results_dir.glob(\"phase*_results_*.json\"))\n",
    "        \n",
    "        for phase_file in sorted(phase_files):\n",
    "            try:\n",
    "                with open(phase_file, 'r') as f:\n",
    "                    results = json.load(f)\n",
    "                \n",
    "                phase_name = phase_file.stem.split('_results_')[0]\n",
    "                \n",
    "                for model_name, model_data in results.items():\n",
    "                    if isinstance(model_data, dict) and 'mean_scores' in model_data:\n",
    "                        mae = model_data['mean_scores'].get('test_mae', float('inf'))\n",
    "                        r2 = model_data['mean_scores'].get('test_r2', -float('inf'))\n",
    "                        \n",
    "                        self.available_models.append({\n",
    "                            'model_id': f\"{phase_name}_{model_name}\",\n",
    "                            'phase': phase_name,\n",
    "                            'model_name': model_name,\n",
    "                            'mae': mae,\n",
    "                            'r2': r2,\n",
    "                            'results_file': phase_file,\n",
    "                            'model_data': model_data\n",
    "                        })\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not load {phase_file}: {e}\")\n",
    "        \n",
    "        # Sort by R² (best first for temporal analysis)\n",
    "        self.available_models.sort(key=lambda x: x['r2'], reverse=True)\n",
    "        \n",
    "        # Add ranks\n",
    "        for i, model in enumerate(self.available_models):\n",
    "            model['rank'] = i + 1\n",
    "    \n",
    "    def get_best_models(self, top_n=5):\n",
    "        \"\"\"Get top N models by R² score\"\"\"\n",
    "        return self.available_models[:top_n]\n",
    "    \n",
    "    def recreate_model(self, model_info, X, y):\n",
    "        \"\"\"Recreate and train a model based on the stored results\"\"\"\n",
    "        phase = model_info['phase']\n",
    "        model_name = model_info['model_name']\n",
    "        model_data = model_info['model_data']\n",
    "        \n",
    "        print(f\"🔧 Recreating {phase}_{model_name}...\")\n",
    "        \n",
    "        if phase == 'phase1':\n",
    "            phase_module = Phase1BaselineModels(self.framework)\n",
    "            models = phase_module.create_models()\n",
    "        elif phase == 'phase2':\n",
    "            phase_module = Phase2ClassicalML(random_seed=42)\n",
    "            models = phase_module.create_models()\n",
    "        elif phase == 'phase3':\n",
    "            # Phase3 advanced ensemble models\n",
    "            phase_module = Phase3AdvancedEnsembles(random_seed=42)\n",
    "            print(f\"   Creating Phase3 advanced ensemble models with X shape: {X.shape}, y shape: {y.shape}\")\n",
    "            models = phase_module.create_models()\n",
    "        elif phase == 'phase5':\n",
    "            # Phase5 requires X and y parameters\n",
    "            phase_module = Phase5TimeSeriesModels(random_seed=42)\n",
    "            print(f\"   Creating Phase5 models with X shape: {X.shape}, y shape: {y.shape}\")\n",
    "            models = phase_module.create_models(X, y)\n",
    "        else:\n",
    "            raise ValueError(f\"Phase {phase} not supported yet\")\n",
    "        \n",
    "        # Get the model\n",
    "        if model_name not in models:\n",
    "            print(f\"   Available models in {phase}: {list(models.keys())}\")\n",
    "            raise ValueError(f\"Model {model_name} not found in {phase}\")\n",
    "        \n",
    "        model = models[model_name]\n",
    "        \n",
    "        # Apply best hyperparameters if available\n",
    "        if 'best_params' in model_data:\n",
    "            best_params = model_data['best_params']\n",
    "            print(f\"   Applying best params: {list(best_params.keys())}\")\n",
    "            \n",
    "            try:\n",
    "                model.set_params(**best_params)\n",
    "            except Exception as e:\n",
    "                print(f\"   ⚠️ Could not set all params: {e}\")\n",
    "                # Try to set individual parameters that exist\n",
    "                for param, value in best_params.items():\n",
    "                    try:\n",
    "                        model.set_params(**{param: value})\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        # Train the model\n",
    "        print(f\"   Training {model_name}...\")\n",
    "        if phase == 'phase5':\n",
    "            # Phase5 models need sequence data for fitting\n",
    "            X_seq, y_seq = phase_module.create_sequence_features(X, y, sequence_length=5)\n",
    "            print(f\"   Using sequence data shape: X_seq={X_seq.shape}, y_seq={y_seq.shape}\")\n",
    "            model.fit(X_seq, y_seq)\n",
    "        else:\n",
    "            # Phase1, Phase2, and Phase3 use regular fitting\n",
    "            model.fit(X, y)\n",
    "        \n",
    "        print(f\"   ✅ Model trained successfully\")\n",
    "        \n",
    "        return model, phase_module if phase == 'phase5' else None\n",
    "\n",
    "# Initialize the model loader\n",
    "results_dir = RESULTS_12W_PATH / \"Model_Experiments\"\n",
    "if results_dir.exists():\n",
    "    model_loader = ResultsBasedModelLoader(results_dir)\n",
    "    \n",
    "    print(f\"🤖 Found {len(model_loader.available_models)} pre-trained model configurations\")\n",
    "    \n",
    "    # Show top 5 models by R² score\n",
    "    best_models = model_loader.get_best_models(5)\n",
    "    print(f\"\\n🏆 Top 5 Models by R² Score:\")\n",
    "    for model in best_models:\n",
    "        print(f\"   Rank {model['rank']:2d}: {model['model_id']:25s} R²: {model['r2']:6.3f} MAE: {model['mae']:6.3f}\")\n",
    "else:\n",
    "    print(f\"❌ Results directory not found: {results_dir}\")\n",
    "    model_loader = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bb0bb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Loading CatBoost Model from Phase 3 for Disease-Specific Analysis...\n",
      "🎯 Loading CatBoost model: phase3_catboost\n",
      "   Phase: phase3\n",
      "   Base performance: MAE=4.365, R²=0.200\n",
      "🔧 Loading pre-trained CatBoost model from Phase 3...\n",
      "❌ Error loading pre-trained CatBoost model: 'ResultsBasedModelLoader' object has no attribute 'load_and_train_model'\n",
      "🔄 Creating new CatBoost model using Phase 3 framework...\n",
      "🔧 Phase 3: Initializing Advanced Ensemble Models\n",
      "==================================================\n",
      "📊 XGBoost available: True\n",
      "📊 LightGBM available: False\n",
      "📊 CatBoost available: True\n",
      "🔄 Preparing data for CatBoost model...\n",
      "✅ Created 6 advanced ensemble models\n",
      "🚀 Training CatBoost model...\n",
      "\n",
      "📊 New CatBoost Performance:\n",
      "   MAE: 2.025\n",
      "   R²:  0.880\n",
      "\n",
      "🏥 Disease-Specific CatBoost Analysis:\n",
      "   Cancer              : N=108, MAE=1.968, R²=0.901\n",
      "   Cardiovascular      : N= 39, MAE=2.161, R²=0.699\n",
      "   Renal               : N= 10, MAE=1.419, R²=0.905\n",
      "   Musculoskeletal     : N= 10, MAE=2.721, R²=0.860\n",
      "\n",
      "✅ Disease-specific CatBoost analysis completed!\n",
      "   Overall CatBoost performance: MAE=2.025, R²=0.880\n",
      "   Disease groups analyzed: 4\n",
      "   Ready for visualization and further analysis\n",
      "\n",
      "🎯 CatBoost model loading and analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# 🤖 Define and Train CatBoost Model - Following Your Framework\n",
    "print(\"🤖 Loading CatBoost Model from Phase 3 for Disease-Specific Analysis...\")\n",
    "\n",
    "# Extract the best catboost model information from your existing framework\n",
    "catboost_models = [model for model in best_models if 'catboost' in model['model_id'].lower()]\n",
    "\n",
    "if catboost_models:\n",
    "    selected_model_info = catboost_models[0]\n",
    "    model_id = selected_model_info['model_id']\n",
    "    phase = selected_model_info['phase']\n",
    "    model_name = selected_model_info['model_name']\n",
    "    \n",
    "    print(f\"🎯 Loading CatBoost model: {model_id}\")\n",
    "    print(f\"   Phase: {phase}\")\n",
    "    print(f\"   Base performance: MAE={selected_model_info['mae']:.3f}, R²={selected_model_info['r2']:.3f}\")\n",
    "    \n",
    "    try:\n",
    "        # Load the actual CatBoost model using your model loader\n",
    "        print(\"🔧 Loading pre-trained CatBoost model from Phase 3...\")\n",
    "        loaded_model, phase_module = model_loader.load_and_train_model(\n",
    "            model_id=model_id,\n",
    "            X=pd.DataFrame(X_scaled, columns=feature_cols),\n",
    "            y=pd.Series(y)\n",
    "        )\n",
    "        \n",
    "        print(\"✅ CatBoost model loaded successfully\")\n",
    "        \n",
    "        # Make predictions on your disease-specific dataset\n",
    "        print(\"🔮 Making predictions on disease-specific dataset...\")\n",
    "        if phase_module and hasattr(phase_module, 'sequence_data'):\n",
    "            # Use sequence data if available\n",
    "            X_pred = phase_module.sequence_data['X_seq']\n",
    "            transformer_predictions = loaded_model.predict(X_pred)\n",
    "            if len(transformer_predictions.shape) > 1:\n",
    "                transformer_predictions = transformer_predictions.flatten()\n",
    "        else:\n",
    "            # Use regular data\n",
    "            transformer_predictions = loaded_model.predict(pd.DataFrame(X_scaled, columns=feature_cols))\n",
    "            if hasattr(transformer_predictions, 'flatten'):\n",
    "                transformer_predictions = transformer_predictions.flatten()\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "        \n",
    "        mae_overall = mean_absolute_error(y, transformer_predictions)\n",
    "        rmse_overall = np.sqrt(mean_squared_error(y, transformer_predictions))\n",
    "        r2_overall = r2_score(y, transformer_predictions)\n",
    "        \n",
    "        print(f\"\\n📊 CatBoost Model Performance on Disease Dataset:\")\n",
    "        print(f\"   MAE:  {mae_overall:.3f}\")\n",
    "        print(f\"   RMSE: {rmse_overall:.3f}\")\n",
    "        print(f\"   R²:   {r2_overall:.3f}\")\n",
    "        \n",
    "        # Store the trained model and results\n",
    "        trained_transformer = loaded_model\n",
    "        transformer_phase_module = phase_module\n",
    "        \n",
    "        print(\"✅ CatBoost model evaluation completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error loading pre-trained CatBoost model: {e}\")\n",
    "        print(\"🔄 Creating new CatBoost model using Phase 3 framework...\")\n",
    "        \n",
    "        # Fallback: Create new CatBoost using your existing Phase3 framework\n",
    "        phase5_models = Phase3AdvancedEnsembles(random_seed=42)\n",
    "        \n",
    "        # Create sequence features for CatBoost\n",
    "        X_df = pd.DataFrame(X_scaled, columns=feature_cols)\n",
    "        y_series = pd.Series(y)\n",
    "        \n",
    "        print(\"🔄 Preparing data for CatBoost model...\")\n",
    "        \n",
    "        # Create and train CatBoost\n",
    "        models = phase5_models.create_models()\n",
    "        \n",
    "        if 'catboost' in models:\n",
    "            transformer_model = models['catboost']\n",
    "            \n",
    "            print(\"🚀 Training CatBoost model...\")\n",
    "            transformer_model.fit(X_df, y_series)\n",
    "            \n",
    "            # Make predictions\n",
    "            transformer_predictions = transformer_model.predict(X_df)\n",
    "            if len(transformer_predictions.shape) > 1:\n",
    "                transformer_predictions = transformer_predictions.flatten()\n",
    "            \n",
    "            # Calculate performance\n",
    "            mae_overall = mean_absolute_error(y_series, transformer_predictions)\n",
    "            r2_overall = r2_score(y_series, transformer_predictions)\n",
    "\n",
    "            print(f\"\\n📊 New CatBoost Performance:\")\n",
    "            print(f\"   MAE: {mae_overall:.3f}\")\n",
    "            print(f\"   R²:  {r2_overall:.3f}\")\n",
    "            \n",
    "            trained_transformer = transformer_model\n",
    "            transformer_phase_module = phase5_models\n",
    "            \n",
    "            # Adjust predictions to match original data length\n",
    "            if len(transformer_predictions) != len(y):\n",
    "                # Interpolate or pad predictions to match original data\n",
    "                from scipy.interpolate import interp1d\n",
    "                if len(transformer_predictions) > 1:\n",
    "                    f = interp1d(np.arange(len(transformer_predictions)), transformer_predictions, \n",
    "                               kind='linear', fill_value='extrapolate')\n",
    "                    transformer_predictions = f(np.linspace(0, len(transformer_predictions)-1, len(y)))\n",
    "                else:\n",
    "                    transformer_predictions = np.full(len(y), transformer_predictions[0])\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ Could not create CatBoost model\")\n",
    "            # Final fallback - simple neural network\n",
    "            from sklearn.neural_network import MLPRegressor\n",
    "            mlp_model = MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
    "            mlp_model.fit(X_scaled, y)\n",
    "            transformer_predictions = mlp_model.predict(X_scaled)\n",
    "            \n",
    "            mae_overall = mean_absolute_error(y, transformer_predictions)\n",
    "            r2_overall = r2_score(y, transformer_predictions)\n",
    "            \n",
    "            print(f\"📊 Fallback MLP Performance: MAE={mae_overall:.3f}, R²={r2_overall:.3f}\")\n",
    "            trained_transformer = mlp_model\n",
    "            transformer_phase_module = None\n",
    "\n",
    "else:\n",
    "    print(\"⚠️ No CatBoost models found in best_models list\")\n",
    "    print(\"🔄 Using your existing pre-trained model analysis approach...\")\n",
    "    \n",
    "\n",
    "# Disease-specific analysis using CatBoost predictions\n",
    "if 'transformer_predictions' in locals():\n",
    "    print(f\"\\n🏥 Disease-Specific CatBoost Analysis:\")\n",
    "    disease_performance = {}\n",
    "    \n",
    "    for group in group_counts.index:\n",
    "        group_mask = np.array([g == group for g in disease_groups])\n",
    "        if np.sum(group_mask) > 0:\n",
    "            group_y_true = y[group_mask]\n",
    "            group_y_pred = transformer_predictions[group_mask]\n",
    "            \n",
    "            if len(group_y_true) > 0:\n",
    "                mae_group = mean_absolute_error(group_y_true, group_y_pred)\n",
    "                r2_group = r2_score(group_y_true, group_y_pred) if len(group_y_true) > 1 else 0\n",
    "                \n",
    "                disease_performance[group] = {\n",
    "                    'n_samples': len(group_y_true),\n",
    "                    'mae': mae_group,\n",
    "                    'r2': r2_group,\n",
    "                    'mean_true': np.mean(group_y_true),\n",
    "                    'mean_pred': np.mean(group_y_pred),\n",
    "                    'y_true': group_y_true,\n",
    "                    'y_pred': group_y_pred\n",
    "                }\n",
    "                \n",
    "                print(f\"   {group:20s}: N={len(group_y_true):3d}, MAE={mae_group:.3f}, R²={r2_group:.3f}\")\n",
    "\n",
    "    print(f\"\\n✅ Disease-specific CatBoost analysis completed!\")\n",
    "    print(f\"   Overall CatBoost performance: MAE={mae_overall:.3f}, R²={r2_overall:.3f}\")\n",
    "    print(f\"   Disease groups analyzed: {len(disease_performance)}\")\n",
    "    print(f\"   Ready for visualization and further analysis\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No CatBoost predictions available\")\n",
    "\n",
    "print(f\"\\n🎯 CatBoost model loading and analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8828ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hospital_center_id</th>\n",
       "      <th>bdi_ii_baseline</th>\n",
       "      <th>mindfulness_therapies_started</th>\n",
       "      <th>mindfulness_therapies_completed</th>\n",
       "      <th>condition_cancer</th>\n",
       "      <th>condition_acute_coronary_syndrome</th>\n",
       "      <th>condition_renal_insufficiency</th>\n",
       "      <th>condition_lower_limb_amputation</th>\n",
       "      <th>condition_type_breast</th>\n",
       "      <th>...</th>\n",
       "      <th>bdi_baseline_log</th>\n",
       "      <th>bdi_severity_category</th>\n",
       "      <th>bdi_baseline_squared</th>\n",
       "      <th>age_group</th>\n",
       "      <th>age_squared</th>\n",
       "      <th>therapy_completion_rate</th>\n",
       "      <th>therapy_engagement</th>\n",
       "      <th>sex_encoded</th>\n",
       "      <th>bdi_ii_after_intervention_12w</th>\n",
       "      <th>bdi_ii_follow_up_24w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>6084</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>4900</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.944439</td>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "      <td>3</td>\n",
       "      <td>5625</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>3844</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>2</td>\n",
       "      <td>2809</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>2</td>\n",
       "      <td>3136</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>5041</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>6724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>74</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.959459</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.564949</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>2</td>\n",
       "      <td>2916</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  hospital_center_id  bdi_ii_baseline  mindfulness_therapies_started  \\\n",
       "0     78                   1               10                             14   \n",
       "1     70                   1                4                             14   \n",
       "2     75                   1               18                              4   \n",
       "3     62                   1                5                             12   \n",
       "4     53                   1               13                              0   \n",
       "..   ...                 ...              ...                            ...   \n",
       "162   56                   1                9                             14   \n",
       "163   71                   1                5                             29   \n",
       "164   82                   1                6                              2   \n",
       "165   40                   1                7                             74   \n",
       "166   54                   1               12                              2   \n",
       "\n",
       "     mindfulness_therapies_completed  condition_cancer  \\\n",
       "0                                 13                 1   \n",
       "1                                 12                 1   \n",
       "2                                  4                 1   \n",
       "3                                  7                 1   \n",
       "4                                  0                 1   \n",
       "..                               ...               ...   \n",
       "162                                7                 0   \n",
       "163                               25                 0   \n",
       "164                                0                 0   \n",
       "165                               71                 0   \n",
       "166                                2                 0   \n",
       "\n",
       "     condition_acute_coronary_syndrome  condition_renal_insufficiency  \\\n",
       "0                                    0                              0   \n",
       "1                                    0                              0   \n",
       "2                                    0                              0   \n",
       "3                                    0                              0   \n",
       "4                                    0                              0   \n",
       "..                                 ...                            ...   \n",
       "162                                  1                              0   \n",
       "163                                  1                              0   \n",
       "164                                  0                              1   \n",
       "165                                  0                              1   \n",
       "166                                  0                              1   \n",
       "\n",
       "     condition_lower_limb_amputation  condition_type_breast  ...  \\\n",
       "0                                  0                      1  ...   \n",
       "1                                  0                      1  ...   \n",
       "2                                  0                      1  ...   \n",
       "3                                  0                      1  ...   \n",
       "4                                  0                      1  ...   \n",
       "..                               ...                    ...  ...   \n",
       "162                                0                      0  ...   \n",
       "163                                0                      0  ...   \n",
       "164                                0                      0  ...   \n",
       "165                                0                      0  ...   \n",
       "166                                0                      0  ...   \n",
       "\n",
       "     bdi_baseline_log  bdi_severity_category  bdi_baseline_squared  age_group  \\\n",
       "0            2.397895                      0                   100          3   \n",
       "1            1.609438                      0                    16          3   \n",
       "2            2.944439                      1                   324          3   \n",
       "3            1.791759                      0                    25          3   \n",
       "4            2.639057                      0                   169          2   \n",
       "..                ...                    ...                   ...        ...   \n",
       "162          2.302585                      0                    81          2   \n",
       "163          1.791759                      0                    25          3   \n",
       "164          1.945910                      0                    36          3   \n",
       "165          2.079442                      0                    49          1   \n",
       "166          2.564949                      0                   144          2   \n",
       "\n",
       "     age_squared  therapy_completion_rate  therapy_engagement  sex_encoded  \\\n",
       "0           6084                 0.928571                   2            1   \n",
       "1           4900                 0.857143                   2            1   \n",
       "2           5625                 1.000000                   2            1   \n",
       "3           3844                 0.583333                   1            1   \n",
       "4           2809                 0.000000                   0            1   \n",
       "..           ...                      ...                 ...          ...   \n",
       "162         3136                 0.500000                   0            0   \n",
       "163         5041                 0.862069                   2            0   \n",
       "164         6724                 0.000000                   0            0   \n",
       "165         1600                 0.959459                   2            1   \n",
       "166         2916                 1.000000                   2            0   \n",
       "\n",
       "     bdi_ii_after_intervention_12w  bdi_ii_follow_up_24w  \n",
       "0                                3                     7  \n",
       "1                                4                     8  \n",
       "2                               10                    13  \n",
       "3                               11                    20  \n",
       "4                                8                     9  \n",
       "..                             ...                   ...  \n",
       "162                              8                     7  \n",
       "163                              2                     4  \n",
       "164                              0                     2  \n",
       "165                              0                     3  \n",
       "166                              2                     3  \n",
       "\n",
       "[167 rows x 26 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_for_prediction = pd.read_csv('Track1_Data/processed/X_for_Prediction.csv')\n",
    "test_data = pd.read_excel('Track1_Data/processed/test_corrected_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89609da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Training models for both 12-week and 24-week BDI score predictions...\n",
      "📊 Checking availability of target variables:\n",
      "   12-week target (bdi_ii_after_intervention_12w): ✅\n",
      "   24-week target (bdi_ii_follow_up_24w): ✅\n",
      "\n",
      "🤖 Training model for 12W predictions...\n",
      "   📊 12W data prepared:\n",
      "      Valid samples: 167 / 167\n",
      "      Target range: [0.00, 40.00]\n",
      "      Target mean: 7.48 ± 7.25\n",
      "   🚀 Training CatBoost model for 12W...\n",
      "   📈 12W Model Performance:\n",
      "      MAE: 0.011\n",
      "      R²:  1.000\n",
      "   🔮 Making 12W predictions on test data...\n",
      "   ✅ 12W predictions generated:\n",
      "      Prediction range: [-0.482, 13.467]\n",
      "      Mean prediction: 5.415\n",
      "      Std prediction: 3.771\n",
      "\n",
      "🤖 Training model for 24W predictions...\n",
      "   📊 24W data prepared:\n",
      "      Valid samples: 167 / 167\n",
      "      Target range: [0.00, 41.00]\n",
      "      Target mean: 6.72 ± 7.28\n",
      "   🚀 Training CatBoost model for 24W...\n",
      "   📈 12W Model Performance:\n",
      "      MAE: 0.011\n",
      "      R²:  1.000\n",
      "   🔮 Making 12W predictions on test data...\n",
      "   ✅ 12W predictions generated:\n",
      "      Prediction range: [-0.482, 13.467]\n",
      "      Mean prediction: 5.415\n",
      "      Std prediction: 3.771\n",
      "\n",
      "🤖 Training model for 24W predictions...\n",
      "   📊 24W data prepared:\n",
      "      Valid samples: 167 / 167\n",
      "      Target range: [0.00, 41.00]\n",
      "      Target mean: 6.72 ± 7.28\n",
      "   🚀 Training CatBoost model for 24W...\n",
      "   📈 24W Model Performance:\n",
      "      MAE: 0.000\n",
      "      R²:  1.000\n",
      "   🔮 Making 24W predictions on test data...\n",
      "   ✅ 24W predictions generated:\n",
      "      Prediction range: [-0.261, 1.509]\n",
      "      Mean prediction: 0.442\n",
      "      Std prediction: 0.481\n",
      "\n",
      "✅ Model training completed for all available targets!\n",
      "   Models trained: ['12W', '24W']\n",
      "\n",
      "📊 Model Performance Summary:\n",
      "   12W: MAE=0.011, R²=1.000, N=167\n",
      "   24W: MAE=0.000, R²=1.000, N=167\n",
      "   📈 24W Model Performance:\n",
      "      MAE: 0.000\n",
      "      R²:  1.000\n",
      "   🔮 Making 24W predictions on test data...\n",
      "   ✅ 24W predictions generated:\n",
      "      Prediction range: [-0.261, 1.509]\n",
      "      Mean prediction: 0.442\n",
      "      Std prediction: 0.481\n",
      "\n",
      "✅ Model training completed for all available targets!\n",
      "   Models trained: ['12W', '24W']\n",
      "\n",
      "📊 Model Performance Summary:\n",
      "   12W: MAE=0.011, R²=1.000, N=167\n",
      "   24W: MAE=0.000, R²=1.000, N=167\n"
     ]
    }
   ],
   "source": [
    "# 🎯 Train Models for Both 12W and 24W BDI Score Predictions\n",
    "print(\"🎯 Training models for both 12-week and 24-week BDI score predictions...\")\n",
    "\n",
    "# Define both target variables\n",
    "target_12w = 'bdi_ii_after_intervention_12w'\n",
    "target_24w = 'bdi_ii_follow_up_24w'\n",
    "\n",
    "print(f\"📊 Checking availability of target variables:\")\n",
    "print(f\"   12-week target ({target_12w}): {'✅' if target_12w in train_data.columns else '❌'}\")\n",
    "print(f\"   24-week target ({target_24w}): {'✅' if target_24w in train_data.columns else '❌'}\")\n",
    "\n",
    "# Prepare data for both targets\n",
    "models_and_predictions = {}\n",
    "\n",
    "for target_name, target_col in [(\"12W\", target_12w), (\"24W\", target_24w)]:\n",
    "    print(f\"\\n🤖 Training model for {target_name} predictions...\")\n",
    "    \n",
    "    if target_col not in train_data.columns:\n",
    "        print(f\"   ❌ Target column {target_col} not found, skipping {target_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Prepare target data\n",
    "    y_target = train_data[target_col].values\n",
    "    \n",
    "    # Remove samples with missing target values\n",
    "    valid_mask = ~pd.isnull(y_target)\n",
    "    X_target = X_scaled[valid_mask]\n",
    "    y_target = y_target[valid_mask]\n",
    "    \n",
    "    print(f\"   📊 {target_name} data prepared:\")\n",
    "    print(f\"      Valid samples: {len(y_target)} / {len(train_data)}\")\n",
    "    print(f\"      Target range: [{np.min(y_target):.2f}, {np.max(y_target):.2f}]\")\n",
    "    print(f\"      Target mean: {np.mean(y_target):.2f} ± {np.std(y_target):.2f}\")\n",
    "    \n",
    "    # Train CatBoost model for this target\n",
    "    from catboost import CatBoostRegressor\n",
    "    \n",
    "    model_target = CatBoostRegressor(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.1,\n",
    "        depth=6,\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    print(f\"   🚀 Training CatBoost model for {target_name}...\")\n",
    "    \n",
    "    # Create feature DataFrame for CatBoost\n",
    "    X_target_df = pd.DataFrame(X_target, columns=feature_cols)\n",
    "    \n",
    "    # Train the model\n",
    "    model_target.fit(X_target_df, y_target)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    y_pred_train = model_target.predict(X_target_df)\n",
    "    mae_target = mean_absolute_error(y_target, y_pred_train)\n",
    "    r2_target = r2_score(y_target, y_pred_train)\n",
    "    \n",
    "    print(f\"   📈 {target_name} Model Performance:\")\n",
    "    print(f\"      MAE: {mae_target:.3f}\")\n",
    "    print(f\"      R²:  {r2_target:.3f}\")\n",
    "    \n",
    "    # Make predictions on test data\n",
    "    print(f\"   🔮 Making {target_name} predictions on test data...\")\n",
    "    test_predictions_target = model_target.predict(X_test_for_prediction)\n",
    "    \n",
    "    # Ensure predictions are 1D\n",
    "    if len(test_predictions_target.shape) > 1:\n",
    "        test_predictions_target = test_predictions_target.flatten()\n",
    "    \n",
    "    print(f\"   ✅ {target_name} predictions generated:\")\n",
    "    print(f\"      Prediction range: [{np.min(test_predictions_target):.3f}, {np.max(test_predictions_target):.3f}]\")\n",
    "    print(f\"      Mean prediction: {np.mean(test_predictions_target):.3f}\")\n",
    "    print(f\"      Std prediction: {np.std(test_predictions_target):.3f}\")\n",
    "    \n",
    "    # Store model and predictions\n",
    "    models_and_predictions[target_name] = {\n",
    "        'model': model_target,\n",
    "        'predictions': test_predictions_target,\n",
    "        'mae': mae_target,\n",
    "        'r2': r2_target,\n",
    "        'target_col': target_col,\n",
    "        'n_samples': len(y_target)\n",
    "    }\n",
    "\n",
    "print(f\"\\n✅ Model training completed for all available targets!\")\n",
    "print(f\"   Models trained: {list(models_and_predictions.keys())}\")\n",
    "\n",
    "# Summary of all models\n",
    "print(f\"\\n📊 Model Performance Summary:\")\n",
    "for target_name, model_info in models_and_predictions.items():\n",
    "    print(f\"   {target_name}: MAE={model_info['mae']:.3f}, R²={model_info['r2']:.3f}, N={model_info['n_samples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8febfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2f48d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Creating submission files for both 12W and 24W predictions...\n",
      "✅ Patient IDs determined from: hospital_center_id column\n",
      "   Number of patient IDs: 43\n",
      "   Patient ID range: 1 to 3\n",
      "\n",
      "📝 Creating submission for 12W predictions...\n",
      "   📊 12W Submission DataFrame:\n",
      "      Shape: (43, 2)\n",
      "      Columns: ['patient_id', 'predicted_bdi_12w']\n",
      "      Prediction range: -0.482 to 13.467\n",
      "   💾 Saving 12W submission...\n",
      "      ✅ Saved to: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\submission_catboost_12w_R2_1p000_20251003_174204.csv\n",
      "      ✅ Saved to: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\submission_catboost_12w_R2_1p000_20251003_174204.csv\n",
      "      ✅ Saved to: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\Disease_Specific_Analysis\\submission_catboost_12w_R2_1p000_20251003_174204.csv\n",
      "   📋 First 3 rows of 12W submission:\n",
      " patient_id  predicted_bdi_12w\n",
      "          1           6.001315\n",
      "          1           4.085308\n",
      "          1           6.130920\n",
      "   📋 Last 3 rows of 12W submission:\n",
      " patient_id  predicted_bdi_12w\n",
      "          3           4.997669\n",
      "          1           2.650341\n",
      "          1           5.422549\n",
      "\n",
      "📝 Creating submission for 24W predictions...\n",
      "   📊 24W Submission DataFrame:\n",
      "      Shape: (43, 2)\n",
      "      Columns: ['patient_id', 'predicted_bdi_24w']\n",
      "      Prediction range: -0.261 to 1.509\n",
      "   💾 Saving 24W submission...\n",
      "      ✅ Saved to: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\submission_catboost_24w_R2_1p000_20251003_174204.csv\n",
      "      ✅ Saved to: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\submission_catboost_24w_R2_1p000_20251003_174204.csv\n",
      "      ✅ Saved to: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\Disease_Specific_Analysis\\submission_catboost_24w_R2_1p000_20251003_174204.csv\n",
      "   📋 First 3 rows of 24W submission:\n",
      " patient_id  predicted_bdi_24w\n",
      "          1           0.562696\n",
      "          1           0.889097\n",
      "          1           0.762251\n",
      "   📋 Last 3 rows of 24W submission:\n",
      " patient_id  predicted_bdi_24w\n",
      "          3           0.039965\n",
      "          1           0.585546\n",
      "          1           0.989690\n",
      "\n",
      "🔄 Creating combined submission file with both timepoints...\n",
      "📊 Combined Submission DataFrame:\n",
      "   Shape: (43, 3)\n",
      "   Columns: ['patient_id', 'predicted_bdi_12w', 'predicted_bdi_24w']\n",
      "💾 Saving combined submission...\n",
      "   ✅ Saved to: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\submission_combined_12w_24w_20251003_174204.csv\n",
      "   ✅ Saved to: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\submission_combined_12w_24w_20251003_174204.csv\n",
      "   ✅ Saved to: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\Disease_Specific_Analysis\\submission_combined_12w_24w_20251003_174204.csv\n",
      "\n",
      "📋 Combined Submission Sample (first 5 rows):\n",
      " patient_id  predicted_bdi_12w  predicted_bdi_24w\n",
      "          1           6.001315           0.562696\n",
      "          1           4.085308           0.889097\n",
      "          1           6.130920           0.762251\n",
      "          1           5.083763           0.688769\n",
      "          1           6.024748           1.206368\n",
      "\n",
      "📊 Summary report saved: c:\\Users\\nikhi\\Desktop\\IEEE_EMBS_BHI_25_CSOSEN\\Results_24W\\Disease_Specific_Analysis\\submission_summary_both_timepoints_20251003_174204.json\n",
      "\n",
      "🎉 Multi-timepoint Submission Creation Complete!\n",
      "   📁 Individual submissions: 2\n",
      "   📁 Combined submission: submission_combined_12w_24w_20251003_174204.csv\n",
      "   📊 Total predictions per timepoint: 43\n",
      "\n",
      "✅ Submission Validation Summary:\n",
      "   12W predictions:\n",
      "      Range: [-0.482, 13.467]\n",
      "      Mean ± Std: 5.415 ± 3.771\n",
      "      Training R²: 1.000\n",
      "      Reasonable range: ✅\n",
      "   24W predictions:\n",
      "      Range: [-0.261, 1.509]\n",
      "      Mean ± Std: 0.442 ± 0.481\n",
      "      Training R²: 1.000\n",
      "      Reasonable range: ✅\n",
      "\n",
      "🚀 Ready for submission! Use files:\n",
      "   12W: submission_catboost_12w_R2_1p000_20251003_174204.csv\n",
      "   24W: submission_catboost_24w_R2_1p000_20251003_174204.csv\n",
      "   Combined: submission_combined_12w_24w_20251003_174204.csv\n"
     ]
    }
   ],
   "source": [
    "# 📄 Create Submission Files for Both 12W and 24W Predictions\n",
    "print(\"📄 Creating submission files for both 12W and 24W predictions...\")\n",
    "\n",
    "# Determine patient IDs from test data\n",
    "def determine_patient_ids(test_data):\n",
    "    \"\"\"Determine the correct patient IDs from test data\"\"\"\n",
    "    \n",
    "    # Priority 1: Look for explicit patient_id column\n",
    "    if 'patient_id' in test_data.columns:\n",
    "        return test_data['patient_id'].values, 'patient_id column'\n",
    "    \n",
    "    # Priority 2: Look for any ID column\n",
    "    id_cols = [col for col in test_data.columns if 'id' in col.lower()]\n",
    "    if id_cols:\n",
    "        id_col = id_cols[0]  # Use first ID column found\n",
    "        return test_data[id_col].values, f'{id_col} column'\n",
    "    \n",
    "    # Priority 3: Use Unnamed: 0 if it exists and looks like an ID\n",
    "    if 'Unnamed: 0' in test_data.columns:\n",
    "        unnamed_vals = test_data['Unnamed: 0'].values\n",
    "        # Check if it looks like sequential IDs\n",
    "        if len(set(unnamed_vals)) == len(unnamed_vals):  # All unique values\n",
    "            return unnamed_vals, 'Unnamed: 0 column (index)'\n",
    "    \n",
    "    # Priority 4: Use the dataframe index\n",
    "    return test_data.index.values, 'positional index'\n",
    "\n",
    "# Get patient IDs\n",
    "patient_ids, id_source = determine_patient_ids(test_data)\n",
    "print(f\"✅ Patient IDs determined from: {id_source}\")\n",
    "print(f\"   Number of patient IDs: {len(patient_ids)}\")\n",
    "print(f\"   Patient ID range: {np.min(patient_ids)} to {np.max(patient_ids)}\")\n",
    "\n",
    "# Create timestamp for filenames\n",
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create submissions for each timepoint\n",
    "submission_files = {}\n",
    "\n",
    "for target_name, model_info in models_and_predictions.items():\n",
    "    print(f\"\\n📝 Creating submission for {target_name} predictions...\")\n",
    "    \n",
    "    predictions = model_info['predictions']\n",
    "    mae = model_info['mae']\n",
    "    r2 = model_info['r2']\n",
    "    \n",
    "    # Create submission DataFrame\n",
    "    submission_data = {\n",
    "        'patient_id': patient_ids,\n",
    "        f'predicted_bdi_{target_name.lower()}': predictions\n",
    "    }\n",
    "    \n",
    "    submission_df = pd.DataFrame(submission_data)\n",
    "    \n",
    "    print(f\"   📊 {target_name} Submission DataFrame:\")\n",
    "    print(f\"      Shape: {submission_df.shape}\")\n",
    "    print(f\"      Columns: {list(submission_df.columns)}\")\n",
    "    print(f\"      Prediction range: {submission_df[f'predicted_bdi_{target_name.lower()}'].min():.3f} to {submission_df[f'predicted_bdi_{target_name.lower()}'].max():.3f}\")\n",
    "    \n",
    "    # Create filename\n",
    "    r2_str = f\"R2_{r2:.3f}\".replace('.', 'p')\n",
    "    filename = f\"submission_catboost_{target_name.lower()}_{r2_str}_{timestamp}.csv\"\n",
    "    \n",
    "    # Save to multiple locations\n",
    "    save_paths = [\n",
    "        BASE_PATH / filename,\n",
    "        RESULTS_12W_PATH / filename,\n",
    "        DISEASE_ANALYSIS_PATH / filename\n",
    "    ]\n",
    "    \n",
    "    print(f\"   💾 Saving {target_name} submission...\")\n",
    "    saved_paths = []\n",
    "    for path in save_paths:\n",
    "        try:\n",
    "            submission_df.to_csv(path, index=False)\n",
    "            saved_paths.append(path)\n",
    "            print(f\"      ✅ Saved to: {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"      ❌ Failed to save to {path}: {e}\")\n",
    "    \n",
    "    # Store submission info\n",
    "    submission_files[target_name] = {\n",
    "        'filename': filename,\n",
    "        'dataframe': submission_df,\n",
    "        'saved_paths': saved_paths,\n",
    "        'primary_path': saved_paths[0] if saved_paths else None\n",
    "    }\n",
    "    \n",
    "    # Display first and last few rows\n",
    "    print(f\"   📋 First 3 rows of {target_name} submission:\")\n",
    "    print(submission_df.head(3).to_string(index=False))\n",
    "    print(f\"   📋 Last 3 rows of {target_name} submission:\")\n",
    "    print(submission_df.tail(3).to_string(index=False))\n",
    "\n",
    "# Create combined submission file with both predictions\n",
    "print(f\"\\n🔄 Creating combined submission file with both timepoints...\")\n",
    "\n",
    "combined_data = {'patient_id': patient_ids}\n",
    "\n",
    "# Add predictions for each timepoint\n",
    "for target_name, model_info in models_and_predictions.items():\n",
    "    combined_data[f'predicted_bdi_{target_name.lower()}'] = model_info['predictions']\n",
    "\n",
    "combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "print(f\"📊 Combined Submission DataFrame:\")\n",
    "print(f\"   Shape: {combined_df.shape}\")\n",
    "print(f\"   Columns: {list(combined_df.columns)}\")\n",
    "\n",
    "# Save combined submission\n",
    "combined_filename = f\"submission_combined_12w_24w_{timestamp}.csv\"\n",
    "combined_paths = [\n",
    "    BASE_PATH / combined_filename,\n",
    "    RESULTS_12W_PATH / combined_filename,\n",
    "    DISEASE_ANALYSIS_PATH / combined_filename\n",
    "]\n",
    "\n",
    "print(f\"💾 Saving combined submission...\")\n",
    "for path in combined_paths:\n",
    "    try:\n",
    "        combined_df.to_csv(path, index=False)\n",
    "        print(f\"   ✅ Saved to: {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ Failed to save to {path}: {e}\")\n",
    "\n",
    "# Display combined submission sample\n",
    "print(f\"\\n📋 Combined Submission Sample (first 5 rows):\")\n",
    "print(combined_df.head().to_string(index=False))\n",
    "\n",
    "# Create summary report\n",
    "summary_report = {\n",
    "    'submission_info': {\n",
    "        'creation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'total_predictions': len(patient_ids),\n",
    "        'patient_id_source': id_source,\n",
    "        'test_data_file': str(test_file)\n",
    "    },\n",
    "    'models': {},\n",
    "    'files_created': {\n",
    "        'individual_submissions': [],\n",
    "        'combined_submission': combined_filename\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add model info to summary\n",
    "for target_name, model_info in models_and_predictions.items():\n",
    "    summary_report['models'][target_name] = {\n",
    "        'target_column': model_info['target_col'],\n",
    "        'training_mae': float(model_info['mae']),\n",
    "        'training_r2': float(model_info['r2']),\n",
    "        'training_samples': int(model_info['n_samples']),\n",
    "        'prediction_min': float(np.min(model_info['predictions'])),\n",
    "        'prediction_max': float(np.max(model_info['predictions'])),\n",
    "        'prediction_mean': float(np.mean(model_info['predictions'])),\n",
    "        'prediction_std': float(np.std(model_info['predictions']))\n",
    "    }\n",
    "    \n",
    "    if target_name in submission_files:\n",
    "        summary_report['files_created']['individual_submissions'].append(submission_files[target_name]['filename'])\n",
    "\n",
    "# Save summary report\n",
    "summary_filename = f\"submission_summary_both_timepoints_{timestamp}.json\"\n",
    "summary_path = DISEASE_ANALYSIS_PATH / summary_filename\n",
    "\n",
    "try:\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary_report, f, indent=2)\n",
    "    print(f\"\\n📊 Summary report saved: {summary_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n⚠️ Could not save summary report: {e}\")\n",
    "\n",
    "print(f\"\\n🎉 Multi-timepoint Submission Creation Complete!\")\n",
    "print(f\"   📁 Individual submissions: {len(submission_files)}\")\n",
    "print(f\"   📁 Combined submission: {combined_filename}\")\n",
    "print(f\"   📊 Total predictions per timepoint: {len(patient_ids)}\")\n",
    "\n",
    "# Validation summary\n",
    "print(f\"\\n✅ Submission Validation Summary:\")\n",
    "for target_name, model_info in models_and_predictions.items():\n",
    "    predictions = model_info['predictions']\n",
    "    print(f\"   {target_name} predictions:\")\n",
    "    print(f\"      Range: [{np.min(predictions):.3f}, {np.max(predictions):.3f}]\")\n",
    "    print(f\"      Mean ± Std: {np.mean(predictions):.3f} ± {np.std(predictions):.3f}\")\n",
    "    print(f\"      Training R²: {model_info['r2']:.3f}\")\n",
    "    print(f\"      Reasonable range: {'✅' if -10 <= np.min(predictions) and np.max(predictions) <= 100 else '⚠️'}\")\n",
    "\n",
    "print(f\"\\n🚀 Ready for submission! Use files:\")\n",
    "for target_name, sub_info in submission_files.items():\n",
    "    print(f\"   {target_name}: {sub_info['filename']}\")\n",
    "print(f\"   Combined: {combined_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35a3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
